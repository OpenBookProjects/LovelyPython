找出两个文件中不同部分

文件A和文件B是两组人名单，每行是一个人的名字。这里我们要完成一个任务，把在文件A中出现，但没有在文件B中的人都找出来。


首先读取文件内容：
>>> a = file('a.txt').readlines()
>>> b = file('b.txt').readlines()
>>> a
['a\n', 'b\n', 'd\n', 'f\n', 'g\n', 'h\n']
>>> b
['b\n', 'c\n', 'e\n', 'f\n']

然后是比较过程：
>>> for i in a:
...     if i not in b:
...         print i.rstrip('\n')
... 
a
d
g
h
>>> 

甚至连写程序都不用，我们就可以在python命令行里直接快速完成。file.readlines可以把文件中所有内容一次读取出来，放到内存中来处理。只有小文件才可以这样用，如果文件过大，内存就会被文件内容吃光，这样程序执行效率返回会下降。然后对文件a中的每一行内容，检查是否在文件b中存在，不存在就直接打印到屏幕上。

如果两个文件的数据量多起来的时候，用list的in操作来判断a里的一个名字在b里是否存在，效率就太差了；这时可以引进一个数据结构：集合(set)。读取文件内容的部分就变成了这样：

>>> a = set(file('a'))
>>> b = set(file('b'))
>>> a
set(['d\n', 'a\n', 'b\n', 'h\n', 'f\n', 'g\n'])
>>> b
set(['c\n', 'f\n', 'b\n', 'e\n'])

这样，比较的部分还是可以继续使用in操作符。读取文件的部分省略了readlines函数，set会自动从文件中读取所有数据。

数据多了，输出也可能会变得多起来，直接打印到屏幕已经不够用了，需要保存到文件中：
>>> f = file('output.txt', 'w')
>>> for i in a:
...     if i not in b:
...         print >>> f, i.rstrip('\n')
>>>

但是，当文件内容大到超出内存的大小时，上面的方法就无法使用了。这时怎么办呢？我们可以先排序，再比较。一旦两个文件被以相同的顺序排列好了，我们就可以“顺流而下”，逐行比较，而不用一次全部装载到内存来了。

1. 大文件排序

一般情况下，我们可以使用系统的sort命令对文件进行排序，但使用python排序文件也是很方便的：
>>> file('sorted.txt', 'w').writelines(sorted(file('filename.txt')))
这一行命令就可以按照升序对文件排序，并保存在一个新文件中。

但对于超大文件，受限于内存的大小，不论是系统提供的sort命令，还是上面使用的python函数，处理起来效率都非常差，甚至因为需要的内存超出系统内存大小无法完成任务。不过不用担心，我们还是有办法来解决的。通过化整为零，把大文件的排序降低难度为多个小文件的排序，然后通过合并算法就可把组合成一个完整的结果了。只要每个小文件足够放到内存中，再加上合并算法对内存的占用也很少，如此一来，大文件处理遇到的内存限制也就迎刃而解。

LINES = 10000
def split_sort(filename):
    f = file(filename)
    num = 0
    while True:
        lines = []
        for i in range(LINES):
            line = f.readline()
            if not line:
                break
            lines.append(line)
        if not lines:
            break
        lines.sort()
        num += 1
        file(filename + '.%d'%num, 'w').writelines(lines)
    return num

这段代码把文件分割成多个排好序的小文件。返回值是文件的个数。首先打开文件，在while循环读取每行数据，直到再没有任何数据，退出循环。在循环中，每读取10000行，就把它们排序，并写入到一个新的文件中，文件名是原名后缀文件序号数字。

from heapq import heappop, heappush

def merge_sorted(filename, num):
    lines = []
    for i in range(num):
        f = file(filename + '.%d'%(i+1))
        line = f.readline()
        if line:
            heappush(lines, (line, f))
    while lines:
        line, f = heappop(lines)
        yield line
        line = f.readline()
        if line:
            heappush(lines, (line, f))

这段代码是把多个排好序的小文件合并成一个文件。首先，从每个文件中读取第一行，把数据和打开的文件一起存入列表lines。while循环把列表当成一个自动排序的队列，每次从里面取第一个元素（也是最小的一个元素），然后返回该值并从这个数据所在的文件中取下一个数据，重新放入队列中。这个过程保证了每次得到的都是当前几个文件中数据里最小的一个，当遍历完所有的已排序文件，这个函数返回的也就是所有数据按照顺序合后的结果。

这个过程使用到了一个特殊的模块：heapq。它是一个把列表当做特殊的队列使用，用heappush把新元素存入队列，用heappop从队列中取出第一个元素；通过这种方法操作，它就可以自动保持队列中的最小值始终排在队列的最前面，这样我们逐个取出的数据就可以保证是顺序排序的。实际上，把heappush的代码替换为：
lines.append((line, f))
lines.sort()
把heappop替换为：
lines.pop(0)
也可以完成同样的功能，但列表排序的执行效率很一般，这在我们处理大数据量时会多花很多不必要的时间，所以我们采用heapq来优化代码、提高执行效率、节省运行时间。

if __name__ == '__main__':
    import sys
    num = split_sort(sys.argv[1])
    output = file(sys.argv[2])
    for line in merge_sorted(sys.argv[1], num):
        outputu.write(line)

这段是把第一个参数的文件进行排序，并把结果保存到第二个参数的文件中。

上面的代码中还缺少一部分功能。看出来了吗？排序过程中生成了许多临时的小文件，但在程序里并没有及时删除。如果读者您有兴趣，不妨试试亲自修改一下这段程序，给它增加删除临时文件的功能。

2. 大文件比较

import sys

def notin(sorted_file_a, sorted_file_b):
    r"""compare two file

    >>> from StringIO import StringIO
    >>>
    >>> a = '\n'.join('abdfgh')
    >>> b = '\n'.join('bcef')
    >>> list(notin(StringIO(a), StringIO(b)))
    ['a', 'd', 'g', 'h']
    """
    fa = sorted_file_a
    fb = sorted_file_b
    fa = isinstance(fa, str) and open(fa) or fa
    fb = isinstance(fb, str) and open(fb) or fb

    sa = fa.readline()
    sb = fb.readline()
    while True:
        if not sa: break
        if not sb: break
        sa = sa.rstrip('\n')
        sb = sb.rstrip('\n')

        compare = cmp(sa, sb)
        if (compare < 0):
            # FILE A only
            yield sa
            sa = fa.readline()
        elif (compare == 0):
            # both
            sa = fa.readline()
            sb = fb.readline()
        else:
            # FILE B only
            sb = fb.readline()

    # print more FILEA
    if sa:
        yield sa.rstrip('\n')
        for sa in fa:
            yield sa

把大文件排好顺序以后，我们就可以按照顺序来逐行读取两个文件；这样，只需顺序读取一次，我们就可以找出A文件中哪些行在B文件中从来没有出现过。在函数的开头，打开两个文件，并读取第一行数据。在下面的while循环中，如果任何一个文件中没有更多数据了，就退出循环。然后用python自带的cmp函数比较两个文件中的当前数据。根据cmp的返回值，如果A的数据小于B的数据，则说明这行数据只在A中存在，它就是我们的目标，把它返回，并读取A中的下一个数据。如果A和B的数据相等，那么这个数据恰好在两个文件中都存在，那么跳过它们，并从A和B两个文件中读取下一个数据，用于下一轮比较。如果A的数据大于B，那么说明这个数据是只有B中存在的，则忽略它，并从B中读取下一个数据。经过这样的循环和比较，大部分的数据就被筛选了出来；但有可能当B中已经读完数据了，而A中还有多余的数据，那么我们就可以肯定，剩下的肯定全部都是A中所特有的，那么就需要把它们依次读取，全部返回。

if __name__ == '__main__':
    notin(sys.argv[1], sys.argv[2])


